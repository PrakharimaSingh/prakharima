{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GJCKPbbSUAQ1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1'\n",
        "response = requests.get(url)\n",
        "html_content = response.content\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Find all the product containers on the page\n",
        "product_containers = soup.find_all('div', class_='s-result-item')\n",
        "\n",
        "# Loop over each product container\n",
        "for container in product_containers:\n",
        "    # Extract the product URL\n",
        "    product_url = container.find('a', class_='a-link-normal')['href']\n",
        "\n",
        "    # Extract the product name\n",
        "    product_name = container.find('span', class_='a-size-medium a-color-base a-text-normal').text\n",
        "\n",
        "    # Extract the product price\n",
        "    product_price = container.find('span', class_='a-offscreen').text\n",
        "\n",
        "    # Extract the product rating\n",
        "    rating = container.find('span', class_='a-icon-alt').text\n",
        "\n",
        "    # Extract the number of reviews\n",
        "    reviews = container.find('div', class_='a-section a-text-normal').text\n"
      ],
      "metadata": {
        "id": "GZdBn7WhUrLC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for page_number in range(1, 21):\n",
        "    url = f'https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&page={page_number}&ref=sr_pg_1'\n",
        "    response = requests.get(url)\n",
        "    html_content = response.content\n",
        "\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Find all the product containers on the page\n",
        "    product_containers = soup.find_all('div', class_='s-result-item')\n",
        "\n",
        "    # Loop over each product container\n",
        "    for container in product_containers:\n",
        "      product_url_element = container.find('a', class_='a-link-normal')\n",
        "\n",
        "      # Check if the product URL element was found\n",
        "      if product_url_element is not None:\n",
        "         product_url = product_url_element['href']\n",
        "      else:\n",
        "         product_url = None\n",
        "\n",
        "      # Extract the product name\n",
        "      product_name_element = container.find('span', class_='a-size-medium a-color-base a-text-normal')\n",
        "      if product_name_element is not None:\n",
        "        product_name = product_name_element.text\n",
        "      else:\n",
        "        product_name = None\n",
        "      # Extract the product price\n",
        "      product_price_element = container.find('span', class_='a-offscreen')\n",
        "      if product_price_element is not None:\n",
        "           product_price = product_price_element.text\n",
        "      else:\n",
        "           product_price = None\n",
        "      # Extract the product rating\n",
        "      rating_element = container.find('span', class_='a-icon-alt')\n",
        "      if rating_element is not None:\n",
        "         rating = rating_element.text\n",
        "      else:\n",
        "         rating = None\n",
        "\n",
        "      # Extract the number of reviews\n",
        "      reviews_element = container.find('div', class_='a-section a-text-normal')\n",
        "      if reviews_element is not None:\n",
        "         reviews = reviews_element.text\n",
        "      else:\n",
        "         reviews = None\n",
        "      # Store the extracted information in a structured format\n",
        "      # ...\n",
        " \n"
      ],
      "metadata": {
        "id": "yX5LxCgvVG3k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the headers for the CSV file\n",
        "headers = ['Product URL', 'Product Name', 'Product Price', 'Rating', 'Number of Reviews']\n",
        "\n",
        "# Open a new file in write mode\n",
        "with open('products.csv', 'w', newline='') as file:\n",
        "    # Create a writer object\n",
        "    writer = csv.DictWriter(file, fieldnames=headers)\n",
        "\n",
        "    # Write the headers to the file\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Iterate over the product information\n",
        "    for container in product_containers:\n",
        "      # Extract the product URL\n",
        "      product_url_element = container.find('a', class_='a-link-normal')\n",
        "      if product_url_element is not None:\n",
        "         product_url = product_url_element['href']\n",
        "      else:\n",
        "         product_url = None\n",
        "\n",
        "      # Extract the product name\n",
        "      product_name_element = container.find('span', class_='a-size-medium a-color-base a-text-normal')\n",
        "      if product_name_element is not None:\n",
        "         product_name = product_name_element.text\n",
        "      else:\n",
        "         product_name = None\n",
        "\n",
        "      # Extract the product price\n",
        "      product_price_element = container.find('span', class_='a-offscreen')\n",
        "      if product_price_element is not None:\n",
        "         product_price = product_price_element.text\n",
        "      else:\n",
        "         product_price = None\n",
        "\n",
        "      # Extract the product rating\n",
        "      rating_element = container.find('span', class_='a-icon-alt')\n",
        "      if rating_element is not None:\n",
        "         rating = rating_element.text\n",
        "      else:\n",
        "         rating = None\n",
        "\n",
        "      # Extract the number of reviews\n",
        "      reviews_element = container.find('div', class_='a-section a-text-normal')\n",
        "      if reviews_element is not None:\n",
        "         reviews = reviews_element.text\n",
        "      else:\n",
        "         reviews = None\n",
        "\n",
        "      # Store the extracted information in a structured format\n",
        "      product_info = {\n",
        "        'Product URL': product_url,\n",
        "        'Product Name': product_name,\n",
        "        'Product Price': product_price,\n",
        "        'Rating': rating,\n",
        "        'Number of Reviews': reviews\n",
        "      }\n",
        "\n",
        "      # Write the product information to the CSV file\n",
        "      writer.writerow(product_info)\n",
        "\n",
        "# Close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "QOIJggHUaA4v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "WSEy7DmJlsKC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_product_info(url):\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse the HTML content of the page\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract the description\n",
        "    description = soup.find('div', id='productDescription').text.strip()\n",
        "\n",
        "    # Extract the ASIN\n",
        "    asin = soup.find('td', text='ASIN')\n",
        "    asin = asin.find_next_sibling().text.strip()\n",
        "\n",
        "    # Extract the product description\n",
        "    product_description = soup.find('td', text='Product Description')\n",
        "    product_description = product_description.find_next_sibling().text.strip()\n",
        "\n",
        "    # Extract the manufacturer\n",
        "    manufacturer = soup"
      ],
      "metadata": {
        "id": "k1uH96e-m_oY"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}